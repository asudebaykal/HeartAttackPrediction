"""
CITED:
1. https://www.kaggle.com/shanan93/brain-mri-segmentation-95-5-accuracy

"""

# -*- coding: utf-8 -*-
"""MRIBrainTumorClassificationAndSegmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E5AcDUSfPR7PL5ZdM740fEX4Ev7mUCsC

## Importing Libraries
"""

import numpy as np
import pandas as pd
import cv2
import tensorflow as tf
from tensorflow.python.keras import Sequential
from tensorflow.keras import layers, optimizers
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.initializers import glorot_uniform
from tensorflow.keras.utils import plot_model
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler
import tensorflow.keras.backend as K
from tensorflow.keras.applications.resnet50 import ResNet50
from keras.applications.vgg16 import VGG16
from keras.losses import binary_crossentropy
import os
import matplotlib.pyplot as plt
import seaborn as sns
import zipfile
from skimage import io
from skimage.color import rgb2gray
import random
import glob
from sklearn.preprocessing import StandardScaler, normalize
from IPython.display import display
from keras_preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import plotly.graph_objs as go
from plotly.offline import init_notebook_mode, iplot

from google.colab import drive
drive.mount('/content/drive')

"""## Data Preparation"""

data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/kaggle_3m/data.csv')
data.head()

data_map = []
for sub_dir_path in glob.glob("/content/drive/MyDrive/Colab Notebooks/kaggle_3m/"+"*"):
    try:
        dir_name = sub_dir_path.split('/')[-1]
        for filename in os.listdir(sub_dir_path):
            image_path = sub_dir_path + '/' + filename
            data_map.extend([dir_name, image_path])
    except Exception as e:
        print(e)

df = pd.DataFrame({"patient_id" : data_map[::2],
                   "path" : data_map[1::2]})
df.head()

df_imgs = df[~df['path'].str.contains("mask")]
df_masks = df[df['path'].str.contains("mask")]

# File path line length images for later sorting
BASE_LEN = 93 # len(kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_ <-!!!43.tif)
END_IMG_LEN = 4 # len(/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_43 !!!->.tif)
END_MASK_LEN = 9 # (/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_43 !!!->_mask.tif)

df_imgs["path"].values

# Data sorting
imgs = sorted(df_imgs["path"].values, key=lambda x : int(x[BASE_LEN:-END_IMG_LEN]))
masks = sorted(df_masks["path"].values, key=lambda x : int(x[BASE_LEN:-END_MASK_LEN]))
idx = random.randint(0, len(imgs)-1)
print("Path to the Image:", imgs[idx], "\nPath to the Mask:", masks[idx])

"""Find if a tumor is detected in the mask by checking the intesity values in the mask"""

brain_df = pd.DataFrame({"patient_id": df_imgs.patient_id.values,
                         "image_path": imgs,
                         "mask_path": masks
                        })
#if all values in the mask is 0 assign 0 to mask column,
#if there are greater values than 0, assign 1 to mask column
def pos_neg_diagnosis(mask_path):
    value = np.max(cv2.imread(mask_path))
    if value > 0 :
        return 1
    else:
        return 0

brain_df['mask'] = brain_df['mask_path'].apply(lambda x: pos_neg_diagnosis(x))
brain_df

brain_df.to_csv('brain_df.csv')
brain_df.info()

"""There are 3929 of FLAIR MRI images. In 1373 of them a tumor detected."""

brain_df['mask'].value_counts()

fig, axs = plt.subplots(1, 3, figsize = (10, 20))
mri_image = io.imread(brain_df.image_path[2500])
axs[0].title.set_text('Brain MRI')
axs[0].imshow(mri_image)
mask_image = io.imread(brain_df.mask_path[2500])
axs[1].title.set_text('Brain MRI Mask')
axs[1].imshow(mask_image,cmap='gray')
mri_image[mask_image == 255] = (0, 255, 0) #Red color
axs[2].title.set_text('MRI with Mask')
axs[2].imshow(mri_image)

# Drop the patient id column
brain_df_train = brain_df.drop(columns = ['patient_id'])
brain_df_train.shape
#Convert the data in the mask column from integer to string format as we will require the data in string format.
brain_df_train['mask'] = brain_df_train['mask'].apply(lambda x: str(x))
brain_df_train.info()

"""### Train, Validation, and Test Data"""

# split the data into train and test data
X_train, X_test2 = train_test_split(brain_df_train, test_size = 0.2)
X_test, X_val = train_test_split(X_test2, test_size = 0.5)

print("train size:", len(X_train))
print("test size:", len(X_test))
print("val size:", len(X_val))

"""### Data Generator"""

EPOCHS = 50
BATCH_SIZE = 32
ImgHieght = 256
ImgWidth = 256
Channels = 3

data_augmentation = dict(rotation_range=0.2,
                        width_shift_range=0.05,
                        height_shift_range=0.05,
                        shear_range=0.05,
                        zoom_range=0.05,
                        horizontal_flip=True,
                        fill_mode='nearest')

#Create a data generator which scales the data from 0 to 1 and makes validation split of 0.15
datagen = ImageDataGenerator(rescale=1./255., **data_augmentation)

train_generator=datagen.flow_from_dataframe(
dataframe=X_train,
directory= './',
x_col='image_path',
y_col='mask',
batch_size=BATCH_SIZE,
shuffle=True,
class_mode="categorical",
target_size=(256,256))

val_datagen=ImageDataGenerator(rescale=1./255., **data_augmentation)

valid_generator=val_datagen.flow_from_dataframe(
dataframe=X_val,
directory= './',
x_col='image_path',
y_col='mask',
batch_size=BATCH_SIZE,
shuffle=True,
class_mode="categorical",
target_size=(256,256))

# Create a data generator for test images
test_datagen=ImageDataGenerator(rescale=1./255., **data_augmentation)

test_generator=test_datagen.flow_from_dataframe(
dataframe=X_test,
directory= './',
x_col='image_path',
y_col='mask',
batch_size=BATCH_SIZE,
shuffle=False,
class_mode='categorical',
target_size=(256,256))

y_train = X_train['mask'].apply(lambda x: int(x))
y_val = X_val['mask'].apply(lambda x: int(x))
y_test = X_test['mask'].apply(lambda x: int(x))
y = dict()
y[0] = []
y[1] = []
for set_name in (y_train,y_val,y_test):
    y[0].append(np.sum(set_name == 0))
    y[1].append(np.sum(set_name == 1))

trace0 = go.Bar(
    x=['Train Set', 'Validation Set', 'Test Set'],
    y=y[0],
    name='No',
    marker=dict(color='orange'),
    opacity=0.7
)
trace1 = go.Bar(
    x=['Train Set', 'Validation Set', 'Test Set'],
    y=y[1],
    name='Yes',
    marker=dict(color='green'),
    opacity=0.7
)

data = [trace0, trace1]
layout = go.Layout(
    title='Count of classes in each set',
    xaxis={'title': 'Set'},
    yaxis={'title': 'Count'}
)
fig = go.Figure(data, layout)
iplot(fig)


"""# Tumor Classification using Transfer Learning

We will use two models from Tensorflow library:
    
    1. ResNet50
    2. VGG16

## ResNet50
"""

# Get the ResNet50 base model (Transfer Learning)
model1 = ResNet50(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256, 256, 3)))
model1.summary()

# freeze the model weights
for layer in model1.layers:
    layers.trainable = False

q = model1.output
q = AveragePooling2D(pool_size = (4,4))(q)
q = Flatten(name= 'flatten')(q)
q = Dense(256, activation = "relu")(q)
q = Dropout(0.3)(q)
q = Dense(256, activation = "relu")(q)
q = Dropout(0.3)(q)
q = Dense(2, activation = 'softmax')(q)

model1 = Model(inputs = model1.input, outputs = q)
model1.summary()

# compile the model
model1.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= ["accuracy"])

# use early stopping to exit training if validation loss is not decreasing even after certain epochs
callbacks = [
    ModelCheckpoint(filepath="model-resnet.hdf5", verbose=1, save_best_only=True),
    EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20),
    ReduceLROnPlateau(monitor='val_loss',mode='min',verbose=1,patience=10,min_delta=0.0001,factor=0.2)
]

"""### Training the ResNet50 Model"""

history1 = model1.fit(train_generator,
              steps_per_epoch= train_generator.n // train_generator.batch_size,
              epochs = EPOCHS,
              validation_data= valid_generator,
              validation_steps= valid_generator.n // valid_generator.batch_size,
              callbacks=callbacks)

# saving model achitecture in json file
model1_json = model1.to_json()
with open("resnet50-model.json", "w") as json_file:
    json_file.write(model1_json)

"""## ResNet50 Model Evaluation"""

history1.history.keys()

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history1.history['loss'])
plt.plot(history1.history['val_loss'])
plt.title("ResNet50 Model LOSS")
plt.ylabel("loss")
plt.xlabel("Epochs")
plt.legend(['train', 'val'])

plt.subplot(1,2,2)
plt.plot(history1.history['accuracy'])
plt.plot(history1.history['val_accuracy'])
plt.title("ResNet50 Model Acc")
plt.ylabel("Accuracy")
plt.xlabel("Epochs")
plt.legend(['train', 'val'])

_, acc = model1.evaluate(test_generator)
print("Test accuracy : {} %".format(acc*100))

prediction = model1.predict(test_generator)

pred = np.argmax(prediction, axis=1)
accuracy = accuracy_score(y_test, pred)
print(accuracy)
original = np.asarray(X_test['mask']).astype('int')

cm = confusion_matrix(original, pred)

report = classification_report(original, pred, labels = [0,1])
print(report)
plt.figure(figsize = (5,5))
sns.heatmap(cm,annot=True)

"""## VGG16"""

model2 = VGG16(weights='imagenet', include_top=False, input_tensor = Input(shape=(256, 256, 3)))
model2.summary()

# freeze the model weights
for layer in model2.layers:
    layers.trainable = False

q = model2.output
q = AveragePooling2D(pool_size = (2,2))(q)
q = Flatten(name= 'flatten')(q)
q = Dense(256, activation = "relu")(q)
q = Dropout(0.3)(q)
q = Dense(256, activation = "relu")(q)
q = Dropout(0.3)(q)
q = Dense(2, activation = 'softmax')(q)

model2 = Model(inputs = model2.input, outputs = q)
model2.summary()

# compile the model
model2.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= ["accuracy"])

# use early stopping to exit training if validation loss is not decreasing even after certain epochs
earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)

# save the model with least validation loss
checkpointer = ModelCheckpoint(filepath="classifier-vgg-weights.hdf5", verbose=1, save_best_only=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss',
                              mode='min',
                              verbose=1,
                              patience=10,
                              min_delta=0.0001,
                              factor=0.2
                             )
callbacks = [checkpointer, earlystopping, reduce_lr]

"""### Training the VGG16 Model"""

history2 = model2.fit(train_generator,
              steps_per_epoch= train_generator.n // train_generator.batch_size,
              epochs = 10,
              validation_data= valid_generator,
              validation_steps= valid_generator.n // valid_generator.batch_size,
              callbacks=[checkpointer, earlystopping])

# saving model achitecture in json file
model2_json = model2.to_json()
with open("vgg16-model.json", "w") as json_file:
    json_file.write(model2_json)

"""## VGG16 Model Evaluation"""

history2.history.keys()

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title("VGG16 Model LOSS")
plt.ylabel("loss")
plt.xlabel("Epochs")
plt.legend(['train', 'val'])

plt.subplot(1,2,2)
plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title("VGG16 Model Acc")
plt.ylabel("Accuracy")
plt.xlabel("Epochs")
plt.legend(['train', 'val'])

_, acc = model2.evaluate(test_generator)
print("Test accuracy : {} %".format(acc*100))

prediction = model2.predict(test_generator)

pred = np.argmax(prediction, axis=1)
#pred = np.asarray(pred).astype('str')
original = np.asarray(X_test['mask']).astype('int')


print(original.shape)
accuracy = accuracy_score(y_test, pred)
print(accuracy)

cm = confusion_matrix(original, pred)

report = classification_report(original, pred, labels = [0,1])
print(report)
plt.figure(figsize = (5,5))
sns.heatmap(cm, annot=True)

"""# Brain MRI Segmentation

## Data Exploration
"""

brain_df.head()

df = brain_df

df_mask1 = brain_df['mask']
df_mask1.shape

"""Get the MRI images where only tumor present"""

masks = brain_df[brain_df['mask'] == 1]
masks.info()

# creating test, train and val sets
X_train, X_val = train_test_split(masks, test_size=0.2)
X_test, X_val = train_test_split(X_val, test_size=0.5)

training = list(X_train.image_path)
training_mask = list(X_train.mask_path)

validation = list(X_val.image_path)
validation_mask= list(X_val.mask_path)

from skimage.io import imread
from skimage.transform import resize
import numpy as np
import math
from tensorflow.keras.utils import Sequence

class DataGenerator(tf.keras.utils.Sequence):

    def __init__(self, ids , mask, image_dir = ' ', batch_size = 16, img_h = 256, img_w = 256, shuffle = True):
        self.ids = ids
        self.mask = mask
        self.image_dir = image_dir
        self.batch_size = batch_size
        self.img_h = img_h
        self.img_w = img_w
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.ids)) / self.batch_size)

    def __getitem__(self, index):
        'Generate a batch of data'
        #generate index of batch_size length
        indexes = self.indexes[index* self.batch_size : (index+1) * self.batch_size]

        #get the ImageId corresponding to the indexes created above based on batch size
        list_ids = [self.ids[i] for i in indexes]

        #get the MaskId corresponding to the indexes created above based on batch size
        list_mask = [self.mask[i] for i in indexes]


        #generate data for the X(features) and y(label)
        X, y = self.__data_generation(list_ids, list_mask)

        #returning the data
        return X, y
    def on_epoch_end(self):
        'Used for updating the indices after each epoch, once at the beginning as well as at the end of each epoch'

        #getting the array of indices based on the input dataframe
        self.indexes = np.arange(len(self.ids))

        #if shuffle is true, shuffle the indices
        if self.shuffle:
            np.random.shuffle(self.indexes)

    def __data_generation(self, list_ids, list_mask):
        'generate the data corresponding the indexes in a given batch of images'

        # create empty arrays of shape (batch_size,height,width,depth)
        #Depth is 3 for input and depth is taken as 1 for output becasue mask consist only of 1 channel.
        X = np.empty((self.batch_size, self.img_h, self.img_w, 3))
        y = np.empty((self.batch_size, self.img_h, self.img_w, 1))

    #iterate through the dataframe rows, whose size is equal to the batch_size
        for i in range(len(list_ids)):
            #path of the image
            img_path = str(list_ids[i])

            #mask path
            mask_path = str(list_mask[i])

            #reading the original image and the corresponding mask image
            img = io.imread(img_path)
            mask = io.imread(mask_path)

            #resizing and coverting them to array of type float64
            img = cv2.resize(img,(self.img_h,self.img_w))
            img = np.array(img, dtype = np.float64)
            mask = cv2.resize(mask,(self.img_h,self.img_w))
            mask = np.array(mask, dtype = np.float64)

            #standardising
            img -= img.mean()
            img /= img.std()

            mask -= mask.mean()
            mask /= mask.std()

            #Adding image to the empty array
            X[i,] = img

            #expanding the dimnesion of the image from (256,256) to (256,256,1)
            y[i,] = np.expand_dims(mask, axis = 2)

        #normalizing y
        y = (y > 0).astype(int)
        return X, y

def UNet(input_size=(256,256,3)):
    inputs = Input(input_size)

    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)
    bn1 = Activation('relu')(conv1)
    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)
    bn1 = BatchNormalization(axis=3)(conv1)
    bn1 = Activation('relu')(bn1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)

    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)
    bn2 = Activation('relu')(conv2)
    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)
    bn2 = BatchNormalization(axis=3)(conv2)
    bn2 = Activation('relu')(bn2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)

    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)
    bn3 = Activation('relu')(conv3)
    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)
    bn3 = BatchNormalization(axis=3)(conv3)
    bn3 = Activation('relu')(bn3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)

    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)
    bn4 = Activation('relu')(conv4)
    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)
    bn4 = BatchNormalization(axis=3)(conv4)
    bn4 = Activation('relu')(bn4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)

    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)
    bn5 = Activation('relu')(conv5)
    conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)
    bn5 = BatchNormalization(axis=3)(conv5)
    bn5 = Activation('relu')(bn5)

    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)
    conv6 = Conv2D(512, (3, 3), padding='same')(up6)
    bn6 = Activation('relu')(conv6)
    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)
    bn6 = BatchNormalization(axis=3)(conv6)
    bn6 = Activation('relu')(bn6)

    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)
    conv7 = Conv2D(256, (3, 3), padding='same')(up7)
    bn7 = Activation('relu')(conv7)
    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)
    bn7 = BatchNormalization(axis=3)(conv7)
    bn7 = Activation('relu')(bn7)

    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)
    conv8 = Conv2D(128, (3, 3), padding='same')(up8)
    bn8 = Activation('relu')(conv8)
    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)
    bn8 = BatchNormalization(axis=3)(conv8)
    bn8 = Activation('relu')(bn8)

    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)
    conv9 = Conv2D(64, (3, 3), padding='same')(up9)
    bn9 = Activation('relu')(conv9)
    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)
    bn9 = BatchNormalization(axis=3)(conv9)
    bn9 = Activation('relu')(bn9)

    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)

    return Model(inputs=[inputs], outputs=[conv10])

# https://github.com/nabsabraham/focal-tversky-unet/blob/master/losses.py
img_rows = 256
img_cols = 256
smooth = 1.
def dsc(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)


def dsc_loss(y_true, y_pred):
    return -dsc(y_true, y_pred)
# Define a custom loss function for ResUNet model
'''
actual link for refrence (https://github.com/nabsabraham/focal-tversky-unet/blob/master/losses.py)
'''

epsilon = 1e-5
smooth = 1

def tversky(y_true, y_pred):
    y_true_pos = K.flatten(y_true)
    y_pred_pos = K.flatten(y_pred)
    true_pos = K.sum(y_true_pos * y_pred_pos)
    false_neg = K.sum(y_true_pos * (1-y_pred_pos))
    false_pos = K.sum((1-y_true_pos)*y_pred_pos)
    alpha = 0.7
    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)

def focal_tversky(y_true,y_pred):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)

    pt_1 = tversky(y_true, y_pred)
    gamma = 0.75
    return K.pow((1-pt_1), gamma)

def tversky_loss(y_true, y_pred):
    return 1 - tversky(y_true,y_pred)

model5 = UNet(input_size=(256,256,3))
model5.summary()

checkpointer = ModelCheckpoint(filepath="Unet-weights.hdf5", verbose=1, save_best_only=True),
earlystopping = EarlyStopping(monitor='val_loss', mode='min',verbose=1,patience=20),
reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min',verbose=1,patience=10,
                              min_delta=0.0001,
                              factor=0.2)

adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)
model5.compile(optimizer = adam, loss = focal_tversky, metrics = [tversky])

train_data = DataGenerator(training, training_mask,16)
val_data = DataGenerator(validation, validation_mask,16)

history5 = model5.fit(train_data,
                  epochs = 72,
                  validation_data = val_data,
                  callbacks = [checkpointer, earlystopping, reduce_lr]
                 )

# saving model achitecture in json file
model5_json = model5.to_json()
with open("U-net-model.json", "w") as json_file:
    json_file.write(model5_json)

history5.history.keys()

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history5.history['loss'])
plt.plot(history5.history['val_loss'])
plt.title("U-Net Model focal tversky Loss")
plt.ylabel("focal tversky loss")
plt.xlabel("Epochs")
plt.legend(['train', 'val'])

plt.subplot(1,2,2)
plt.plot(history5.history['tversky'])
plt.plot(history5.history['val_tversky'])
plt.title("U-Net Model tversky score")
plt.ylabel("tversky Accuracy")
plt.xlabel("Epochs")
plt.legend(['train', 'val'])

test_ids = list(X_test.image_path)
test_mask = list(X_test.mask_path)
test_data = DataGenerator(test_ids, test_mask)
_, tv = model5.evaluate(test_data)
print("Segmentation tversky is {:.2f}%".format(tv*100))


def prediction(test, model, model_seg):
    # empty list to store results
    mask, image_id, has_mask = [], [], []
    #itetrating through each image in test data
    for i in test.image_path:

        img = io.imread(i)
        #normalizing
        img = img *1./255.
        #reshaping
        img = cv2.resize(img, (256,256))
        # converting img into array
        img = np.array(img, dtype=np.float64)
        #reshaping the image from 256,256,3 to 1,256,256,3
        img = np.reshape(img, (1,256,256,3))

        #making prediction for tumor in image
        is_defect = model.predict(img)

        #if tumour is not present we append the details of the image to the list
        if np.argmax(is_defect)==0:
            image_id.append(i)
            has_mask.append(0)
            mask.append('No mask :)')
            continue

        #Creating a empty array of shape 1,256,256,1
        X = np.empty((1,256,256,3))
        # read the image
        img = io.imread(i)
        #resizing the image and coverting them to array of type float64
        img = cv2.resize(img, (256,256))
        img = np.array(img, dtype=np.float64)

        # standardising the image
        img -= img.mean()
        img /= img.std()
        #converting the shape of image from 256,256,3 to 1,256,256,3
        X[0,] = img

        #make prediction of mask
        predict = model_seg.predict(X)

        # if sum of predicted mask is 0 then there is not tumour
        if predict.round().astype(int).sum()==0:
            image_id.append(i)
            has_mask.append(0)
            mask.append('No mask :)')
        else:
        #if the sum of pixel values are more than 0, then there is tumour
            image_id.append(i)
            has_mask.append(1)
            mask.append(predict)

    return pd.DataFrame({'image_path': image_id,'predicted_mask': mask,'has_mask': has_mask})

# making prediction
# model1 for the ResNet50 classification model
# model5 for the brain segmentation model
df_pred = prediction(test_data, model1, model5)
df_pred

# merging original and prediction df
df_pred = test_data.merge(df_pred, on='image_path')
df_pred.head(10)

"""## Localization Performance Evaluation"""
count = 0
fig, axs = plt.subplots(15,5, figsize=(30,70))

for i in range(len(df_pred)):
    if df_pred.has_mask[i]==1 and count<15:
        #read mri images
        img = io.imread(df_pred.image_path[i])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        axs[count][0].imshow(img)
        axs[count][0].title.set_text('Brain MRI')

        #read original mask
        mask = io.imread(df_pred.mask_path[i])
        axs[count][1].imshow(mask)
        axs[count][1].title.set_text('Original Mask')

        #read predicted mask
        pred = np.array(df_pred.predicted_mask[i]).squeeze().round()
        axs[count][2].imshow(pred)
        axs[count][2].title.set_text('AI predicted mask')

        #overlay original mask with MRI
        img[mask==255] = (255,0,0)
        axs[count][3].imshow(img)
        axs[count][3].title.set_text('Brain MRI with original mask (Ground Truth)')

        #overlay predicted mask and MRI
        img_ = io.imread(df_pred.image_path[i])
        img_ = cv2.cvtColor(img_, cv2.COLOR_BGR2RGB)
        img_[pred==1] = (0,255,150)
        axs[count][4].imshow(img_)
        axs[count][4].title.set_text('MRI with AI PREDICTED MASK')
        count +=1
    if (count==15):
        break

fig.tight_layout()

# make prediction
test_predict = model5.predict(test_generator, steps = test_generator.n // 16, verbose =1)

# Obtain the predicted class from the model prediction
predict = []
for i in test_predict:
    predict.append(str(np.argmax(i)))
predict = np.asarray(predict)